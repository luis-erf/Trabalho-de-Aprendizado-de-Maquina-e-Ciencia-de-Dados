# -*- coding: utf-8 -*-
"""Cópia de LSTM_teste.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CG4zcfui4EbkLbRLLpmwXe-qQa43W03l

# imports e installs
"""

# Imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import datasets
from sklearn.svm import SVC, SVR
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error
from sklearn.datasets import make_classification, make_regression, make_circles, make_moons
import warnings
warnings.filterwarnings('ignore')


"""#carregamento e limpeza dos dados"""

df_2010 = pd.read_csv('INMET_S_RS_A801_PORTO ALEGRE_01-01-2010_A_31-12-2010.CSV', encoding='latin1', sep=';', skiprows=8)

df_2011 = pd.read_csv('INMET_S_RS_A801_PORTO ALEGRE_01-01-2011_A_31-12-2011.CSV', encoding='latin1', sep=';', skiprows=8)

df_2012 = pd.read_csv('INMET_S_RS_A801_PORTO ALEGRE_01-01-2012_A_31-12-2012.CSV', encoding='latin1', sep=';', skiprows=8)

df = pd.concat([df_2010, df_2011, df_2012], axis=0)

df.info()

# identificação de colunas que deveriam ser inteiros mas estão como string
object_cols = df.select_dtypes(include='object').columns
numeric_cols_to_convert = [
    'PRECIPITAÇÃO TOTAL, HORÁRIO (mm)',
    'PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA (mB)',
    'PRESSÃO ATMOSFERICA MAX.NA HORA ANT. (AUT) (mB)',
    'PRESSÃO ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB)',
    'RADIACAO GLOBAL (KJ/m²)',
    'TEMPERATURA DO AR - BULBO SECO, HORARIA (°C)',
    'TEMPERATURA DO PONTO DE ORVALHO (°C)',
    'TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)',
    'TEMPERATURA MÍNIMA NA HORA ANT. (AUT) (°C)',
    'TEMPERATURA ORVALHO MAX. NA HORA ANT. (AUT) (°C)',
    'TEMPERATURA ORVALHO MIN. NA HORA ANT. (AUT) (°C)',
    'VENTO, RAJADA MAXIMA (m/s)',
    'VENTO, VELOCIDADE HORARIA (m/s)'
]

# transformando as strings em inteiro e lidando com dados faltantes NaM (que no dataset são '-9999')
for col in numeric_cols_to_convert:
    if col in df.columns:
        df[col] = df[col].astype(str).str.replace(',', '.', regex=False)
        df[col] = pd.to_numeric(df[col], errors='coerce')
        df[col] = df[col].replace(-9999, np.nan)

# lidando com valores -9999 em colunas que já estão em inteiro
humidity_wind_cols = [
    'UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)',
    'UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)',
    'UMIDADE RELATIVA DO AR, HORARIA (%)',
    'VENTO, DIREÇÃO HORARIA (gr) (° (gr))'
]

for col in humidity_wind_cols:
    if col in df.columns:
        df[col] = df[col].replace(-9999, np.nan)

# retirando a coluna 19 ela não apresenta nome e parece ser um erro do dataset
if 'Unnamed: 19' in df.columns:
    df = df.drop(columns=['Unnamed: 19'])

# acrescentando indice DATETIME no lugar das colunas 'DATA (YYYY-MM-DD)' e 'HORA (UTC)'
df['DATETIME'] = pd.to_datetime(df['DATA (YYYY-MM-DD)'] + ' ' + df['HORA (UTC)'].str.replace(':', ''), format='%Y-%m-%d %H%M')
df = df.set_index('DATETIME')
if 'DATA (YYYY-MM-DD)' in df.columns:
    df = df.drop(columns=['DATA (YYYY-MM-DD)'])
if 'HORA (UTC)' in df.columns:
    df = df.drop(columns=['HORA (UTC)'])


print("Dataset após conversão dos valores")

df.info()

# vendo valores nulos no data set
df.isnull().sum()

# 'RADIACAO GLOBAL (KJ/m²)' apresentou um número muito grande de valores faltantes, por isso foi removido
if 'RADIACAO GLOBAL (KJ/m²)' in df.columns:
    df.drop('RADIACAO GLOBAL (KJ/m²)', axis=1, inplace=True)
    print(">> Coluna 'Radiacao' removida.")

base = df.fillna(method='ffill')
base.isnull().sum()

# verificando outliers nas colunas numéricas com boxplots para ter noção de quais variaveis podem ser exogenas

numeric_cols_df = base.select_dtypes(include=np.number)
numeric_columns = numeric_cols_df.columns.tolist()

num_cols_per_row = 4
num_rows = (len(numeric_columns) + num_cols_per_row - 1) // num_cols_per_row

plt.figure(figsize=(num_cols_per_row * 5, num_rows * 4))

for i, col in enumerate(numeric_columns):
    plt.subplot(num_rows, num_cols_per_row, i + 1)
    sns.boxplot(y=base[col])
    plt.title(col, fontsize=10)
    plt.ylabel('')
    plt.xticks([])

plt.tight_layout()
plt.suptitle('Boxplots para as coluna numéricas da base', y=1.02, fontsize=16)
plt.show()

"""#treinando o modelo com o ano de 2002/2003 e testando com 2020 **sem variáveis exógenas**

"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler

#Divisão do dataset em treino e teste
temp_treino_sem_exogena = base[base.index.year == 2010]
treino_sem_exogena = temp_treino_sem_exogena['TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)']
temp_validacao_sem_exogena = base[base.index.year == 2011]
validacao_sem_exogena = temp_validacao_sem_exogena['TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)']

# --- FUNÇÃO AUXILIAR PARA CRIAR O TEMPO CÍCLICO ---
def adicionar_tempo_ciclico(df):
    df_copy = df.copy()

    # Se o índice não for datetime, converta-o (descomente a linha abaixo se necessário)
    # df_copy.index = pd.to_datetime(df_copy.index)

    # 1. Transformação da HORA (Ciclo Diário)
    # Permite ao modelo aprender ciclo dia/noite
    df_copy['hora_sin'] = np.sin(2 * np.pi * df_copy.index.hour / 24)
    df_copy['hora_cos'] = np.cos(2 * np.pi * df_copy.index.hour / 24)

    # 2. Transformação do DIA DO ANO (Ciclo Anual - Substitui Mês e Dia)
    # Permite ao modelo aprender Verão/Inverno de forma contínua
    df_copy['dia_ano_sin'] = np.sin(2 * np.pi * df_copy.index.dayofyear / 365.25)
    df_copy['dia_ano_cos'] = np.cos(2 * np.pi * df_copy.index.dayofyear / 365.25)

    return df_copy

# 1. Aplicar a transformação nos DataFrames
temp_treino_sem_exogena_proc = adicionar_tempo_ciclico(temp_treino_sem_exogena)
temp_validacao_sem_exogena_proc = adicionar_tempo_ciclico(temp_validacao_sem_exogena)

# 2. Defina as colunas
target_column = 'TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)'
# As novas colunas exógenas agora são matemáticas (Seno/Cosseno)
exog_columns = ['hora_sin', 'hora_cos', 'dia_ano_sin', 'dia_ano_cos']

# 3. Extraia e escale APENAS a variável alvo (Temperatura)
# Variáveis exógenas (Sin/Cos) JÁ estão na escala correta (-1 a 1), não precisam de Scaler.
treino_target_sem_exogena = temp_treino_sem_exogena_proc[target_column].values.reshape(-1, 1)
val_target_sem_exogena = temp_validacao_sem_exogena_proc[target_column].values.reshape(-1, 1)

target_scaler_sem_exogena = StandardScaler()
treino_target_scaled_sem_exogena = target_scaler_sem_exogena.fit_transform(treino_target_sem_exogena)
val_target_scaled_sem_exogena = target_scaler_sem_exogena.transform(val_target_sem_exogena)

print("Shape do Alvo Treino:", treino_target_scaled_sem_exogena.shape)

import numpy as np

# 1. Combinar Temperatura (Escalada) com Tempo (Seno/Cosseno)
# A estrutura será: [Temperatura, Hora_Sin, Hora_Cos, DiaAno_Sin, DiaAno_Cos]
# treino_combined_data = np.hstack((treino_target_scaled, treino_exog))
# val_combined_data = np.hstack((val_target_scaled, val_exog))

treino_combined_data_sem_exogena = treino_target_scaled_sem_exogena
val_combined_data_sem_exogena = val_target_scaled_sem_exogena

# 2. Verificar shapes
print("Shape final dos dados de treino:", treino_combined_data_sem_exogena.shape)
print("Shape final dos dados de validação:", val_combined_data_sem_exogena.shape)

# O resultado deve ter 5 colunas (1 alvo + 4 tempo)
print("Primeiras 5 linhas do treino:\n", treino_combined_data_sem_exogena[:5])

import numpy as np

def create_multivariate_sequences(data, sequence_length):
    X, y = [], []
    # O loop para antes de estourar o array
    for i in range(len(data) - sequence_length):
        # X: Pega todas as colunas (Temp + Tempo) do passo atual até o tamanho da janela
        X.append(data[i:(i + sequence_length), :])

        # y: Pega APENAS a temperatura (coluna 0) do PRÓXIMO passo
        y.append(data[i + sequence_length, 0])

    return np.array(X), np.array(y)

sequence_length_sem_exogena = 12 # Renamed from sequence_length for clarity

# Criação das sequências
X_train_final_sem_exogena, y_train_final_sem_exogena = create_multivariate_sequences(treino_combined_data_sem_exogena, sequence_length_sem_exogena)
X_val_final_sem_exogena, y_val_final_sem_exogena = create_multivariate_sequences(val_combined_data_sem_exogena, sequence_length_sem_exogena)

print("Shape of X_train_final:", X_train_final_sem_exogena.shape) # Deve ser (N, sequence lenght, 1)
print("Shape of y_train_final:", y_train_final_sem_exogena.shape) # Deve ser (N,)
print("Shape of X_val_final:", X_val_final_sem_exogena.shape)
print("Shape of y_val_final:", y_val_final_sem_exogena.shape)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=10,
    mode='min',
    restore_best_weights=True
)

model_sem_exogena = Sequential()

# Input Shape será (24, 5)
# O modelo vai aprender: "Dada a temperatura E a hora das últimas 24h, qual a temp agora?"
model_sem_exogena.add(LSTM(units=64, activation='relu', return_sequences=False,
               input_shape=(X_train_final_sem_exogena.shape[1], X_train_final_sem_exogena.shape[2])))

model_sem_exogena.add(Dense(units=1)) # Saída: Previsão da Temperatura Escalonada

model_sem_exogena.compile(optimizer='adam', loss='mean_squared_error')

model_sem_exogena.summary()

history_sem_exogena = model_sem_exogena.fit(
    X_train_final_sem_exogena,
    y_train_final_sem_exogena,
    epochs=100,
    batch_size=32,
    verbose=1,
    validation_data=(X_val_final_sem_exogena, y_val_final_sem_exogena),
    callbacks=[early_stopping]
)

print("Treinamento concluído.")

import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

# 1. Previsão (O modelo cospe dados na escala normalizada)
predictions_scaled_sem_exogena = model_sem_exogena.predict(X_val_final_sem_exogena)

# 2. Desfazer a escala (Voltar para Graus Celsius)
# Usamos o target_scaler que treinamos lá no início
predictions_real_sem_exogena = target_scaler_sem_exogena.inverse_transform(predictions_scaled_sem_exogena)
y_val_real_sem_exogena = target_scaler_sem_exogena.inverse_transform(y_val_final_sem_exogena.reshape(-1, 1))

# 3. Calcular Erro
mse_sem_exogena_val = mean_squared_error(y_val_real_sem_exogena, predictions_real_sem_exogena)
print(f"MSE na Validação: {mse_sem_exogena_val:.4f}")

# 4. Plotagem (Zoom em 200 horas para ver os detalhes)
plt.figure(figsize=(20, 6))
# Vamos plotar apenas as primeiras 200 horas para facilitar a visualização do ciclo dia/noite
limit = 10000
plt.plot(y_val_real_sem_exogena[:limit], label='Temperatura Real', color='blue')
plt.plot(predictions_real_sem_exogena[:limit], label='Previsão do Modelo', color='orange', linestyle='--')

plt.title('Validação: Real vs Predito (Primeiras 1000 horas)')
plt.xlabel('Horas')
plt.ylabel('Temperatura (°C)')
plt.legend()
plt.grid(True, alpha=0.5)
plt.show()

"""## testando para o ano de 2020"""

target_column = 'TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)'
temp_teste_sem_exogena = base[base.index.year == 2012]
# 1. Extrair a variável alvo do novo dataset
# Precisamos dela para comparar se o modelo acertou depois (y_true)
teste_target_sem_exogena = temp_teste_sem_exogena[target_column].values.reshape(-1, 1)

# --- PONTO CRÍTICO DE SEGURANÇA ---
# Usamos .transform(), NÃO .fit_transform()
# Estamos dizendo: "Use a régua do treino para medir esses dados novos"
teste_target_scaled_sem_exogena = target_scaler_sem_exogena.transform(teste_target_sem_exogena)

# 3. Combinar (Target Escalado + Exógenas Cíclicas)
teste_combined_data_sem_exogena = teste_target_scaled_sem_exogena
print("Shape dos dados de teste prontos:", teste_combined_data_sem_exogena.shape)

# 1. Criar as sequências (Janelas)
# Reutilizamos a função create_multivariate_sequences
X_teste_ext_sem_exogena, y_teste_ext_sem_exogena = create_multivariate_sequences(teste_combined_data_sem_exogena, sequence_length_sem_exogena)

print("Shape de entrada para o modelo:", X_teste_ext_sem_exogena.shape)

# 2. Fazer a Predição
predictions_ext_scaled_sem_exogena = model_sem_exogena.predict(X_teste_ext_sem_exogena)

# 3. Desfazer a escala para ver os graus Celsius reais
predictions_ext_real_sem_exogena = target_scaler_sem_exogena.inverse_transform(predictions_ext_scaled_sem_exogena)
y_teste_real_sem_exogena = target_scaler_sem_exogena.inverse_transform(y_teste_ext_sem_exogena.reshape(-1, 1))

import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Calcular erros
mse_ext_sem_exogena = mean_squared_error(y_teste_real_sem_exogena, predictions_ext_real_sem_exogena)
mae_ext_sem_exogena = mean_absolute_error(y_teste_real_sem_exogena, predictions_ext_real_sem_exogena)
print(f"mse : {mse_ext_sem_exogena:.2f}")
print(f"Erro Médio Absoluto (MAE) no Novo Dataset: {mae_ext_sem_exogena:.2f} °C")
print(f"Isso significa que o modelo erra, em média, {mae_ext_sem_exogena:.2f} graus para cima ou para baixo.")

# Plotar um trecho
plt.figure(figsize=(21, 6))
limit = 10000 # Visualizar as primeiras 300 horas
plt.plot(y_teste_real_sem_exogena[:limit], label='Real (Dataset Novo)', color='green')
plt.plot(predictions_ext_real_sem_exogena[:limit], label='Predição', color='red', linestyle='--')
plt.title('Teste em Dataset Desconhecido (Out-of-Sample)')
plt.legend()
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import pandas as pd

# 1. Recuperar as datas originais correspondentes às predições
# Lembre-se: O modelo "come" as primeiras X horas (sequence_length) para fazer a primeira predição.
# Então, as datas das predições começam a partir do índice [sequence_length] do dataframe original.

# Usar a sequence_length correta (que é a segunda dimensão de X_teste_ext)
prediction_sequence_length_sem_exogena = X_teste_ext_sem_exogena.shape[1]
datas_correspondentes_sem_exogena = temp_teste_sem_exogena.index[prediction_sequence_length_sem_exogena:]

# Vamos garantir que os tamanhos batem (segurança)
print(f"Tamanho das Datas: {len(datas_correspondentes_sem_exogena)}")
print(f"Tamanho das Predições: {len(predictions_ext_real_sem_exogena)}")

# 2. Criar um DataFrame temporário para facilitar a plotagem
df_resultado_sem_exogena = pd.DataFrame({
    'Real': y_teste_real_sem_exogena.flatten(),
    'Predito': predictions_ext_real_sem_exogena.flatten()
}, index=datas_correspondentes_sem_exogena)

# 3. Plotagem Formatada por Mês
fig, ax = plt.subplots(figsize=(21, 6))

ax.plot(df_resultado_sem_exogena.index, df_resultado_sem_exogena['Real'], label='Temperatura Real', color='green', linewidth=1, alpha=0.7)
ax.plot(df_resultado_sem_exogena.index, df_resultado_sem_exogena['Predito'], label='Previsão do Modelo', color='red', linewidth=1, alpha=0.8, linestyle='--')

# --- FORMATAÇÃO DO EIXO X (A Mágica acontece aqui) ---
# Define o formatador para mostrar o nome do mês (ex: Jan, Fev...)
ax.xaxis.set_major_locator(mdates.MonthLocator()) # Coloca um "tick" a cada mês
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b/%Y')) # Formato: "Jan/2022"

plt.title('Comparação Real vs Predito ao Longo dos Meses')
plt.xlabel('Data')
plt.ylabel('Temperatura (°C)')
plt.legend()
plt.grid(True, alpha=0.5)
plt.xticks(rotation=45) # Gira as datas para não encavalar
plt.tight_layout()
plt.show()

"""#treinando o modelo com o ano de 2002/2003 e testando com 2020 **com variáveis exógenas apenas DateTime**

"""

#Divisão do dataset em treino e teste
temp_treino_com_exogena = base[base.index.year == 2010]
treino_com_exogena = temp_treino_com_exogena['TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)']
temp_validacao_com_exogena = base[base.index.year == 2011]
validacao_com_exogena = temp_validacao_com_exogena['TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)']

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler

# --- FUNÇÃO AUXILIAR PARA CRIAR O TEMPO CÍCLICO ---
def adicionar_tempo_ciclico(df):
    df_copy = df.copy()

    # Se o índice não for datetime, converta-o (descomente a linha abaixo se necessário)
    # df_copy.index = pd.to_datetime(df_copy.index)

    # 1. Transformação da HORA (Ciclo Diário)
    # Permite ao modelo aprender ciclo dia/noite
    df_copy['hora_sin'] = np.sin(2 * np.pi * df_copy.index.hour / 24)
    df_copy['hora_cos'] = np.cos(2 * np.pi * df_copy.index.hour / 24)

    # 2. Transformação do DIA DO ANO (Ciclo Anual - Substitui Mês e Dia)
    # Permite ao modelo aprender Verão/Inverno de forma contínua
    df_copy['dia_ano_sin'] = np.sin(2 * np.pi * df_copy.index.dayofyear / 365.25)
    df_copy['dia_ano_cos'] = np.cos(2 * np.pi * df_copy.index.dayofyear / 365.25)

    return df_copy

# 1. Aplicar a transformação nos DataFrames
temp_treino_com_exogena_proc = adicionar_tempo_ciclico(temp_treino_com_exogena)
temp_validacao_com_exogena_proc = adicionar_tempo_ciclico(temp_validacao_com_exogena)

# 2. Defina as colunas
target_column = 'TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)'
# As novas colunas exógenas agora são matemáticas (Seno/Cosseno)
exog_columns = ['hora_sin', 'hora_cos', 'dia_ano_sin', 'dia_ano_cos']

# 3. Extraia e escale APENAS a variável alvo (Temperatura)
# Variáveis exógenas (Sin/Cos) JÁ estão na escala correta (-1 a 1), não precisam de Scaler.
treino_target_com_exogena = temp_treino_com_exogena_proc[target_column].values.reshape(-1, 1)
val_target_com_exogena = temp_validacao_com_exogena_proc[target_column].values.reshape(-1, 1)

target_scaler_com_exogena = StandardScaler()
treino_target_scaled_com_exogena = target_scaler_com_exogena.fit_transform(treino_target_com_exogena)
val_target_scaled_com_exogena = target_scaler_com_exogena.transform(val_target_com_exogena)

# 4. Extraia as variáveis exógenas (sem aplicar StandardScaler nelas)
treino_exog = temp_treino_com_exogena_proc[exog_columns].values
val_exog = temp_validacao_com_exogena_proc[exog_columns].values

print("Shape do Alvo Treino:", treino_target_scaled_com_exogena.shape)
print("Shape das Exógenas Treino:", treino_exog.shape)
print("Exemplo de Exógena (Hora Sin/Cos, Ano Sin/Cos):\n", treino_exog[:2])

"""MUDANÇA PARA COM OU SEM EXOGENA"""

import numpy as np

# 1. Combinar Temperatura (Escalada) com Tempo (Seno/Cosseno)
# A estrutura será: [Temperatura, Hora_Sin, Hora_Cos, DiaAno_Sin, DiaAno_Cos]
treino_combined_data_com_exogena = np.hstack((treino_target_scaled_com_exogena, treino_exog))
val_combined_data_com_exogena = np.hstack((val_target_scaled_com_exogena, val_exog))

# treino_combined_data = treino_target_scaled
# val_combined_data = val_target_scaled

# 2. Verificar shapes
print("Shape final dos dados de treino:", treino_combined_data_com_exogena.shape)
print("Shape final dos dados de validação:", val_combined_data_com_exogena.shape)

# O resultado deve ter 5 colunas (1 alvo + 4 tempo)
print("Primeiras 5 linhas do treino:\n", treino_combined_data_com_exogena[:5])

import numpy as np

def create_multivariate_sequences(data, sequence_length):
    X, y = [], []
    # O loop para antes de estourar o array
    for i in range(len(data) - sequence_length):
        # X: Pega todas as colunas (Temp + Tempo) do passo atual até o tamanho da janela
        X.append(data[i:(i + sequence_length), :])

        # y: Pega APENAS a temperatura (coluna 0) do PRÓXIMO passo
        y.append(data[i + sequence_length, 0])

    return np.array(X), np.array(y)

sequence_length_com_exogena = 8

# Criação das sequências
X_train_final_com_exogena, y_train_final_com_exogena = create_multivariate_sequences(treino_combined_data_com_exogena, sequence_length_com_exogena)
X_val_final_com_exogena, y_val_final_com_exogena = create_multivariate_sequences(val_combined_data_com_exogena, sequence_length_com_exogena)

print("Shape of X_train_final:", X_train_final_com_exogena.shape) # Deve ser (N, sequence lenght, 1 ou 5)
print("Shape of y_train_final:", y_train_final_com_exogena.shape) # Deve ser (N,)
print("Shape of X_val_final:", X_val_final_com_exogena.shape)
print("Shape of y_val_final:", y_val_final_com_exogena.shape)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=10,
    mode='min',
    restore_best_weights=True
)

model_com_exogena = Sequential()

# Input Shape será (24, 5)
# O modelo vai aprender: "Dada a temperatura E a hora das últimas 24h, qual a temp agora?"
model_com_exogena.add(LSTM(units=64, activation='relu', return_sequences=False,
               input_shape=(X_train_final_com_exogena.shape[1], X_train_final_com_exogena.shape[2])))

model_com_exogena.add(Dense(units=1)) # Saída: Previsão da Temperatura Escalonada

model_com_exogena.compile(optimizer='adam', loss='mean_squared_error')

model_com_exogena.summary()

history_com_exogena = model_com_exogena.fit(
    X_train_final_com_exogena,
    y_train_final_com_exogena,
    epochs=100,
    batch_size=32,
    verbose=1,
    validation_data=(X_val_final_com_exogena, y_val_final_com_exogena),
    callbacks=[early_stopping]
)

print("Treinamento concluído.")

import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

# 1. Previsão (O modelo cospe dados na escala normalizada)
predictions_scaled_com_exogena = model_com_exogena.predict(X_val_final_com_exogena)

# 2. Desfazer a escala (Voltar para Graus Celsius)
# Usamos o target_scaler que treinamos lá no início
predictions_real_com_exogena = target_scaler_com_exogena.inverse_transform(predictions_scaled_com_exogena)
y_val_real_com_exogena = target_scaler_com_exogena.inverse_transform(y_val_final_com_exogena.reshape(-1, 1))

# 3. Calcular Erro
mse_com_exogena_val = mean_squared_error(y_val_real_com_exogena, predictions_real_com_exogena)
print(f"MSE na Validação: {mse_com_exogena_val:.4f}")

# 4. Plotagem (Zoom em 200 horas para ver os detalhes)
plt.figure(figsize=(20, 6))
# Vamos plotar apenas as primeiras 200 horas para facilitar a visualização do ciclo dia/noite
limit = 10000
plt.plot(y_val_real_com_exogena[:limit], label='Temperatura Real', color='blue')
plt.plot(predictions_real_com_exogena[:limit], label='Previsão do Modelo', color='orange', linestyle='--')

plt.title('Validação: Real vs Predito (Primeiras 1000 horas)')
plt.xlabel('Horas')
plt.ylabel('Temperatura (°C)')
plt.legend()
plt.grid(True, alpha=0.5)
plt.show()

"""## testando para o ano de 2020"""

# 2. Aplique EXATAMENTE a mesma função de engenharia de features usada no treino
# (A função adicionar_tempo_ciclico que criamos antes)
temp_teste_com_exogena = base[base.index.year == 2012]
temp_teste_com_exogena = adicionar_tempo_ciclico(temp_teste_com_exogena)

# 3. Defina as colunas (estas foram definidas em TPvT--6bxOIw, redefinindo para clareza)
target_column = 'TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)'
exog_columns= ['hora_sin', 'hora_cos', 'dia_ano_sin', 'dia_ano_cos']

# Verifique se não há NaNs (o shift ou cálculo pode gerar nulos nas pontas)
temp_teste_com_exogena = temp_teste_com_exogena.dropna()

"""MUDANÇA PARA COM OU SEM EXOGENA"""

# 1. Extrair a variável alvo do novo dataset
# Precisamos dela para comparar se o modelo acertou depois (y_true)
teste_target_com_exogena = temp_teste_com_exogena[target_column].values.reshape(-1, 1)

# 2. Extrair as exógenas (Seno/Cosseno e físicas)
teste_exog_com_exogena = temp_teste_com_exogena[exog_columns].values
# --- PONTO CRÍTICO DE SEGURANÇA ---
# Usamos .transform(), NÃO .fit_transform()
# Estamos dizendo: "Use a régua do treino para medir esses dados novos"
teste_target_scaled_com_exogena = target_scaler_com_exogena.transform(teste_target_com_exogena)

# 3. Combinar (Target Escalado + Exógenas Cíclicas + Exógenas Físicas Escaladas)
teste_combined_data_com_exogena = np.hstack((teste_target_scaled_com_exogena, teste_exog_com_exogena))

print("Shape dos dados de teste prontos:", teste_combined_data_com_exogena.shape)

# 1. Criar as sequências (Janelas)
# Reutilizamos a função create_multivariate_sequences
X_teste_ext_com_exogena, y_teste_ext_com_exogena = create_multivariate_sequences(teste_combined_data_com_exogena, sequence_length_com_exogena)

print("Shape de entrada para o modelo:", X_teste_ext_com_exogena.shape)

# 2. Fazer a Predição
predictions_ext_scaled_com_exogena = model_com_exogena.predict(X_teste_ext_com_exogena)

# 3. Desfazer a escala para ver os graus Celsius reais
predictions_ext_real_com_exogena = target_scaler_com_exogena.inverse_transform(predictions_ext_scaled_com_exogena)
y_teste_real_com_exogena = target_scaler_com_exogena.inverse_transform(y_teste_ext_com_exogena.reshape(-1, 1))

import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Calcular erros
mse_ext_com_exogena = mean_squared_error(y_teste_real_com_exogena, predictions_ext_real_com_exogena)
mae_ext_com_exogena = mean_absolute_error(y_teste_real_com_exogena, predictions_ext_real_com_exogena)
print(f"mse : {mse_ext_com_exogena:.2f}")
print(f"Erro Médio Absoluto (MAE) no Novo Dataset: {mae_ext_com_exogena:.2f} °C")
print(f"Isso significa que o modelo erra, em média, {mae_ext_com_exogena:.2f} graus para cima ou para baixo.")

# Plotar um trecho
plt.figure(figsize=(21, 6))
limit = 10000 # Visualizar as primeiras 300 horas
plt.plot(y_teste_real_com_exogena[:limit], label='Real (Dataset Novo)', color='green')
plt.plot(predictions_ext_real_com_exogena[:limit], label='Predição', color='red', linestyle='--')
plt.title('Teste em Dataset Desconhecido (Out-of-Sample)')
plt.legend()
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import pandas as pd

# 1. Recuperar as datas originais correspondentes às predições
# Lembre-se: O modelo "come" as primeiras X horas (sequence_length) para fazer a primeira predição.
# Então, as datas das predições começam a partir do índice [sequence_length] do dataframe original.

# Usar a sequence_length correta (que é a segunda dimensão de X_teste_ext)
prediction_sequence_length_com_exogena = X_teste_ext_com_exogena.shape[1]
datas_correspondentes_com_exogena = temp_teste_com_exogena.index[prediction_sequence_length_com_exogena:]

# Vamos garantir que os tamanhos batem (segurança)
print(f"Tamanho das Datas: {len(datas_correspondentes_com_exogena)}")
print(f"Tamanho das Predições: {len(predictions_ext_real_com_exogena)}")

# 2. Criar um DataFrame temporário para facilitar a plotagem
df_resultado_com_exogena = pd.DataFrame({
    'Real': y_teste_real_com_exogena.flatten(),
    'Predito': predictions_ext_real_com_exogena.flatten()
}, index=datas_correspondentes_com_exogena)

# 3. Plotagem Formatada por Mês
fig, ax = plt.subplots(figsize=(21, 6))

ax.plot(df_resultado_com_exogena.index, df_resultado_com_exogena['Real'], label='Temperatura Real', color='green', linewidth=1, alpha=0.7)
ax.plot(df_resultado_com_exogena.index, df_resultado_com_exogena['Predito'], label='Previsão do Modelo', color='red', linewidth=1, alpha=0.8, linestyle='--')

# --- FORMATAÇÃO DO EIXO X (A Mágica acontece aqui) ---
# Define o formatador para mostrar o nome do mês (ex: Jan, Fev...)
ax.xaxis.set_major_locator(mdates.MonthLocator()) # Coloca um "tick" a cada mês
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b/%Y')) # Formato: "Jan/2022"

plt.title('Comparação Real vs Predito ao Longo dos Meses')
plt.xlabel('Data')
plt.ylabel('Temperatura (°C)')
plt.legend()
plt.grid(True, alpha=0.5)
plt.xticks(rotation=45) # Gira as datas para não encavalar
plt.tight_layout()
plt.show()

"""#treinando o modelo com o ano de 2002/2003 e testando com 2020 **com variáveis exógenas DateTime e fisicas**"""

#Divisão do dataset em treino e teste
temp_treino_multi_exogena = base[base.index.year == 2010]
treino_multi_exogena = temp_treino_multi_exogena['TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)']
temp_validacao_multi_exogena = base[base.index.year == 2011]
validacao_multi_exogena = temp_validacao_multi_exogena['TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)']

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler

# --- FUNÇÃO AUXILIAR PARA CRIAR O TEMPO CÍCLICO ---
def adicionar_tempo_ciclico(df):
    df_copy = df.copy()

    # Se o índice não for datetime, converta-o (descomente a linha abaixo se necessário)
    # df_copy.index = pd.to_datetime(df_copy.index)

    # 1. Transformação da HORA (Ciclo Diário)
    # Permite ao modelo aprender ciclo dia/noite
    df_copy['hora_sin'] = np.sin(2 * np.pi * df_copy.index.hour / 24)
    df_copy['hora_cos'] = np.cos(2 * np.pi * df_copy.index.hour / 24)

    # 2. Transformação do DIA DO ANO (Ciclo Anual - Substitui Mês e Dia)
    # Permite ao modelo aprender Verão/Inverno de forma contínua
    df_copy['dia_ano_sin'] = np.sin(2 * np.pi * df_copy.index.dayofyear / 365.25)
    df_copy['dia_ano_cos'] = np.cos(2 * np.pi * df_copy.index.dayofyear / 365.25)

    return df_copy

# 1. Aplicar a transformação nos DataFrames
temp_treino_multi_exogena_proc = adicionar_tempo_ciclico(temp_treino_multi_exogena)
temp_validacao_multi_exogena_proc = adicionar_tempo_ciclico(temp_validacao_multi_exogena)

# 2. Defina as colunas
target_column = 'TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)'

exog_columns_datetime = ['hora_sin', 'hora_cos', 'dia_ano_sin', 'dia_ano_cos']
exog_columns_fisicas = [
    'PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA (mB)',
    'UMIDADE RELATIVA DO AR, HORARIA (%)',
    'VENTO, RAJADA MAXIMA (m/s)'
]

# 3. Extraia e escale APENAS a variável alvo (Temperatura)
treino_target_multi_exogena = temp_treino_multi_exogena_proc[target_column].values.reshape(-1, 1)
val_target_multi_exogena = temp_validacao_multi_exogena_proc[target_column].values.reshape(-1, 1)

target_scaler_multi_exogena = StandardScaler()
treino_target_scaled_multi_exogena = target_scaler_multi_exogena.fit_transform(treino_target_multi_exogena)
val_target_scaled_multi_exogena = target_scaler_multi_exogena.transform(val_target_multi_exogena)

# 4. Extraia as variáveis exógenas
treino_exog_datetime = temp_treino_multi_exogena_proc[exog_columns_datetime].values
val_exog_datetime = temp_validacao_multi_exogena_proc[exog_columns_datetime].values

treino_exog_fisicas = temp_treino_multi_exogena_proc[exog_columns_fisicas].values
val_exog_fisicas = temp_validacao_multi_exogena_proc[exog_columns_fisicas].values

# Scale the fisicas exogenous variables
fisicas_exog_scaler = StandardScaler()
treino_exog_fisicas_scaled = fisicas_exog_scaler.fit_transform(treino_exog_fisicas)
val_exog_fisicas_scaled = fisicas_exog_scaler.transform(val_exog_fisicas)

# Combine all scaled/prepared exogenous features
treino_multi_exogena = np.hstack((treino_exog_datetime, treino_exog_fisicas_scaled))
val_multi_exogena = np.hstack((val_exog_datetime, val_exog_fisicas_scaled))

print("Shape do Alvo Treino:", treino_target_scaled_multi_exogena.shape)
print("Shape das Exógenas Treino:", treino_multi_exogena.shape)
print("Exemplo de Exógena (Hora Sin/Cos, Ano Sin/Cos, Físicas Escalonadas):\n", treino_multi_exogena[:2])

"""MUDANÇA PARA COM OU SEM EXOGENA"""

import numpy as np

# 1. Combinar Temperatura (Escalada) com Tempo (Seno/Cosseno) e Exógenas Físicas Escaladas
# A estrutura será: [Temperatura, Hora_Sin, Hora_Cos, DiaAno_Sin, DiaAno_Cos, P_ATM, UMIDADE, VENTO_RAJADA]
treino_combined_data_multi_exogena = np.hstack((treino_target_scaled_multi_exogena, treino_multi_exogena))
val_combined_data_multi_exogena = np.hstack((val_target_scaled_multi_exogena, val_multi_exogena))

# 2. Verificar shapes
print("Shape final dos dados de treino:", treino_combined_data_multi_exogena.shape)
print("Shape final dos dados de validação:", val_combined_data_multi_exogena.shape)

# O resultado deve ter 8 colunas (1 alvo + 4 tempo + 3 físicas)
print("Primeiras 5 linhas do treino:\n", treino_combined_data_multi_exogena[:5])

import numpy as np

def create_multivariate_sequences(data, sequence_length):
    X, y = [], []
    # O loop para antes de estourar o array
    for i in range(len(data) - sequence_length):
        # X: Pega todas as colunas (Temp + Tempo) do passo atual até o tamanho da janela
        X.append(data[i:(i + sequence_length), :])

        # y: Pega APENAS a temperatura (coluna 0) do PRÓXIMO passo
        y.append(data[i + sequence_length, 0])

    return np.array(X), np.array(y)

sequence_length_multi_exogena = 8

# Criação das sequências
X_train_final_multi_exogena, y_train_final_multi_exogena = create_multivariate_sequences(treino_combined_data_multi_exogena, sequence_length_multi_exogena)
X_val_final_multi_exogena, y_val_final_multi_exogena = create_multivariate_sequences(val_combined_data_multi_exogena, sequence_length_multi_exogena)

print("Shape of X_train_final:", X_train_final_multi_exogena.shape) # Deve ser (N, sequence lenght, 1 ou 5)
print("Shape of y_train_final:", y_train_final_multi_exogena.shape) # Deve ser (N,)
print("Shape of X_val_final:", X_val_final_multi_exogena.shape)
print("Shape of y_val_final:", y_val_final_multi_exogena.shape)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=10,
    mode='min',
    restore_best_weights=True
)

model_multi_exogena = Sequential()

# Input Shape será (24, 5)
# O modelo vai aprender: "Dada a temperatura E a hora das últimas 24h, qual a temp agora?"
model_multi_exogena.add(LSTM(units=64, activation='relu', return_sequences=False,
               input_shape=(X_train_final_multi_exogena.shape[1], X_train_final_multi_exogena.shape[2])))

model_multi_exogena.add(Dense(units=1)) # Saída: Previsão da Temperatura Escalonada

model_multi_exogena.compile(optimizer='adam', loss='mean_squared_error')

model_multi_exogena.summary()

history_multi_exogena = model_multi_exogena.fit(
    X_train_final_multi_exogena,
    y_train_final_multi_exogena,
    epochs=100,
    batch_size=32,
    verbose=1,
    validation_data=(X_val_final_multi_exogena, y_val_final_multi_exogena),
    callbacks=[early_stopping]
)

print("Treinamento concluído.")

import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

# 1. Previsão (O modelo cospe dados na escala normalizada)
predictions_scaled_multi_exogena = model_multi_exogena.predict(X_val_final_multi_exogena)

# 2. Desfazer a escala (Voltar para Graus Celsius)
# Usamos o target_scaler que treinamos lá no início
predictions_real_multi_exogena = target_scaler_multi_exogena.inverse_transform(predictions_scaled_multi_exogena)
y_val_real_multi_exogena = target_scaler_multi_exogena.inverse_transform(y_val_final_multi_exogena.reshape(-1, 1))

# 3. Calcular Erro
mse_multi_exogena_val = mean_squared_error(y_val_real_multi_exogena, predictions_real_multi_exogena)
print(f"MSE na Validação: {mse_multi_exogena_val:.4f}")

# 4. Plotagem (Zoom em 200 horas para ver os detalhes)
plt.figure(figsize=(20, 6))
# Vamos plotar apenas as primeiras 200 horas para facilitar a visualização do ciclo dia/noite
limit = 10000
plt.plot(y_val_real_multi_exogena[:limit], label='Temperatura Real', color='blue')
plt.plot(predictions_real_multi_exogena[:limit], label='Previsão do Modelo', color='orange', linestyle='--')

plt.title('Validação: Real vs Predito (Primeiras 1000 horas)')
plt.xlabel('Horas')
plt.ylabel('Temperatura (°C)')
plt.legend()
plt.grid(True, alpha=0.5)
plt.show()

"""## testando para o ano de 2020"""

# 2. Aplique EXATAMENTE a mesma função de engenharia de features usada no treino
# (A função adicionar_tempo_ciclico que criamos antes)
temp_teste_multi_exogena = base[base.index.year == 2012]
temp_teste_multi_exogena = adicionar_tempo_ciclico(temp_teste_multi_exogena)

# 3. Selecione as mesmas colunas
target_column = 'TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)'
exog_columns_datetime = ['hora_sin', 'hora_cos', 'dia_ano_sin', 'dia_ano_cos']
exog_columns_fisicas = [
    'PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA (mB)',
    'UMIDADE RELATIVA DO AR, HORARIA (%)',
    'VENTO, RAJADA MAXIMA (m/s)'
]

# Verifique se não há NaNs (o shift ou cálculo pode gerar nulos nas pontas)
temp_teste_multi_exogena = temp_teste_multi_exogena.dropna()

"""MUDANÇA PARA COM OU SEM EXOGENA"""

# 1. Extrair a variável alvo do novo dataset
# Precisamos dela para comparar se o modelo acertou depois (y_true)
teste_target_multi_exogena = temp_teste_multi_exogena[target_column].values.reshape(-1, 1)

# 2. Extrair as exógenas (Seno/Cosseno)
teste_exog_datetime = temp_teste_multi_exogena[exog_columns_datetime].values
teste_exog_fisicas = temp_teste_multi_exogena[exog_columns_fisicas].values

teste_exog_fisicas_scaled = fisicas_exog_scaler.transform(teste_exog_fisicas)
teste_multi_exogena = np.hstack((teste_exog_datetime, teste_exog_fisicas_scaled))
# --- PONTO CRÍTICO DE SEGURANÇA ---
# Usamos .transform(), NÃO .fit_transform()
# Estamos dizendo: "Use a régua do treino para medir esses dados novos"
teste_target_scaled_multi_exogena = target_scaler_multi_exogena.transform(teste_target_multi_exogena)

# 3. Combinar (Target Escalado + Exógenas Cíclicas)
teste_combined_data_multi_exogena = np.hstack((teste_target_scaled_multi_exogena, teste_multi_exogena))
# teste_combined_data = teste_target_scaled
print("Shape dos dados de teste prontos:", teste_combined_data_multi_exogena.shape)

# 1. Criar as sequências (Janelas)
# Reutilizamos a função create_multivariate_sequences
X_teste_ext_multi_exogena, y_teste_ext_multi_exogena = create_multivariate_sequences(teste_combined_data_multi_exogena, sequence_length_multi_exogena)

print("Shape de entrada para o modelo:", X_teste_ext_multi_exogena.shape)

# 2. Fazer a Predição
predictions_ext_scaled_multi_exogena = model_multi_exogena.predict(X_teste_ext_multi_exogena)

# 3. Desfazer a escala para ver os graus Celsius reais
predictions_ext_real_multi_exogena = target_scaler_multi_exogena.inverse_transform(predictions_ext_scaled_multi_exogena)
y_teste_real_multi_exogena = target_scaler_multi_exogena.inverse_transform(y_teste_ext_multi_exogena.reshape(-1, 1))

import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Calcular erros
mse_ext_multi_exogena = mean_squared_error(y_teste_real_multi_exogena, predictions_ext_real_multi_exogena)
mae_ext_multi_exogena = mean_absolute_error(y_teste_real_multi_exogena, predictions_ext_real_multi_exogena)
print(f"mse : {mse_ext_multi_exogena:.2f}")
print(f"Erro Médio Absoluto (MAE) no Novo Dataset: {mae_ext_multi_exogena:.2f} °C")
print(f"Isso significa que o modelo erra, em média, {mae_ext_multi_exogena:.2f} graus para cima ou para baixo.")

# Plotar um trecho
plt.figure(figsize=(21, 6))
limit = 10000 # Visualizar as primeiras 300 horas
plt.plot(y_teste_real_multi_exogena[:limit], label='Real (Dataset Novo)', color='green')
plt.plot(predictions_ext_real_multi_exogena[:limit], label='Predição', color='red', linestyle='--')
plt.title('Teste em Dataset Desconhecido (Out-of-Sample)')
plt.legend()
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import pandas as pd

# 1. Recuperar as datas originais correspondentes às predições
# Lembre-se: O modelo "come" as primeiras X horas (sequence_length) para fazer a primeira predição.
# Então, as datas das predições começam a partir do índice [sequence_length] do dataframe original.

# Usar a sequence_length correta (que é a segunda dimensão de X_teste_ext)
prediction_sequence_length_multi_exogena = X_teste_ext_multi_exogena.shape[1]
datas_correspondentes_multi_exogena = temp_teste_multi_exogena.index[prediction_sequence_length_multi_exogena:]

# Vamos garantir que os tamanhos batem (segurança)
print(f"Tamanho das Datas: {len(datas_correspondentes_multi_exogena)}")
print(f"Tamanho das Predições: {len(predictions_ext_real_multi_exogena)}")

# 2. Criar um DataFrame temporário para facilitar a plotagem
df_resultado_multi_exogena = pd.DataFrame({
    'Real': y_teste_real_multi_exogena.flatten(),
    'Predito': predictions_ext_real_multi_exogena.flatten()
}, index=datas_correspondentes_multi_exogena)

# 3. Plotagem Formatada por Mês
fig, ax = plt.subplots(figsize=(21, 6))

ax.plot(df_resultado_multi_exogena.index, df_resultado_multi_exogena['Real'], label='Temperatura Real', color='green', linewidth=1, alpha=0.7)
ax.plot(df_resultado_multi_exogena.index, df_resultado_multi_exogena['Predito'], label='Previsão do Modelo', color='red', linewidth=1, alpha=0.8, linestyle='--')

# --- FORMATAÇÃO DO EIXO X (A Mágica acontece aqui) ---
# Define o formatador para mostrar o nome do mês (ex: Jan, Fev...)
ax.xaxis.set_major_locator(mdates.MonthLocator()) # Coloca um "tick" a cada mês
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b/%Y')) # Formato: "Jan/2022"

plt.title('Comparação Real vs Predito ao Longo dos Meses')
plt.xlabel('Data')
plt.ylabel('Temperatura (°C)')
plt.legend()
plt.grid(True, alpha=0.5)
plt.xticks(rotation=45) # Gira as datas para não encavalar
plt.tight_layout()
plt.show()

#função para ver diferentes lags no treinamento e o resultado que eles tem no conjunto de teste externo

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_error

def train_and_evaluate_lstm(sequence_length, treino_combined_data, val_combined_data,teste_combined_data,  target_scaler):
    # 1. Create multivariate sequences
    X_train_final, y_train_final = create_multivariate_sequences(treino_combined_data, sequence_length)
    X_val_final, y_val_final = create_multivariate_sequences(val_combined_data, sequence_length)
    X_teste_ext, y_teste_ext = create_multivariate_sequences(teste_combined_data, sequence_length)

    # 2. Initialize EarlyStopping callback
    early_stopping = EarlyStopping(
        monitor='val_loss',
        patience=10,
        mode='min',
        restore_best_weights=True
    )

    # 3. Define the LSTM model
    model = Sequential()
    model.add(LSTM(units=64, activation='relu', return_sequences=False,
                   input_shape=(X_train_final.shape[1], X_train_final.shape[2])))
    model.add(Dense(units=1)) # Output: Scaled Temperature Prediction

    # 4. Compile the model
    model.compile(optimizer='adam', loss='mean_squared_error')

    # 5. Train the model
    history = model.fit(
        X_train_final,
        y_train_final,
        epochs=100,
        batch_size=32,
        verbose=0, # Suppress verbose output for cleaner iteration
        validation_data=(X_val_final, y_val_final),
        callbacks=[early_stopping]
    )

    # 6. Make predictions and inverse transform
    predictions_scaled = model.predict(X_teste_ext, verbose=0)
    predictions_real = target_scaler.inverse_transform(predictions_scaled)
    y_teste_real = target_scaler.inverse_transform(y_teste_ext.reshape(-1, 1))

    # 7. Calculate evaluation metrics
    mse = mean_squared_error(y_teste_real, predictions_real)
    mae = mean_absolute_error(y_teste_real, predictions_real)

    return model, mse, mae, history

"""# tunagem de parametros para exogenas date_time"""

import keras_tuner as kt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam


early_stopping_tunning = EarlyStopping(
    monitor='val_loss',
    patience=5,
    mode='min',
    restore_best_weights=True
)

early_stopping_final = EarlyStopping(
    monitor='val_loss',
    patience=10,
    mode='min',
    restore_best_weights=True
)

def build_model(hp):
    model = Sequential()

    # 1. Tunando o número de neurônios (Units)
    # Ele vai testar: 32, 64, 96, 128, ... até 256
    hp_units = hp.Int('units', min_value=32, max_value=256, step=32)

    # 2. Tunando a Taxa de Aprendizado (Learning Rate)
    # Ele vai escolher entre os valores da lista
    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])

    # 3. Tunando número de camadas LSTM (Opcional, mas poderoso)
    # Vamos permitir 1 ou 2 camadas LSTM
    hp_layers = hp.Int('num_layers', 1, 2)

    # 4. Tunando Dropout (para evitar overfitting)
    hp_dropout = hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)

    if hp_layers == 1:
        # Se for 1 camada, return_sequences=False
        model.add(LSTM(units=hp_units,
                       activation='relu',
                       return_sequences=False,
                       input_shape=(X_train_final_com_exogena.shape[1], X_train_final_com_exogena.shape[2])))
        model.add(Dropout(hp_dropout))

    else:
        # Se forem 2 camadas, a primeira precisa de return_sequences=True
        model.add(LSTM(units=hp_units,
                       activation='relu',
                       return_sequences=True,
                       input_shape=(X_train_final_com_exogena.shape[1], X_train_final_com_exogena.shape[2])))
        model.add(Dropout(hp_dropout))

        # Segunda camada
        model.add(LSTM(units=hp_units, activation='relu', return_sequences=False))
        model.add(Dropout(hp_dropout))

    model.add(Dense(1))

    model.compile(optimizer=Adam(learning_rate=hp_learning_rate),
                  loss='mean_squared_error')

    return model

# --- Configurando o Random Search ---

tuner = kt.RandomSearch(
    build_model,
    objective='val_loss', # Queremos minimizar a perda na validação
    max_trials=50,        # Quantas combinações diferentes ele vai testar (aumente se tiver tempo)
    executions_per_trial=1, # Quantas vezes rodar cada combinação para tirar média (1 é mais rápido)
    directory='tuner_dir',  # Pasta onde salva os logs
    project_name='lstm_temperatura'
)

# Resumo do espaço de busca
tuner.search_space_summary()

# --- Rodando a busca ---
# A gente passa os mesmos callbacks (EarlyStopping) para economizar tempo
tuner.search(X_train_final_com_exogena, y_train_final_com_exogena,
             epochs=50, # Use menos épocas na busca para ser rápido
             validation_data=(X_val_final_com_exogena, y_val_final_com_exogena),
             callbacks=[early_stopping_tunning],
             verbose=1)

# --- Pegando o melhor modelo ---
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]

print(f"""
A melhor busca resultou em:
Units: {best_hps.get('units')}
Learning Rate: {best_hps.get('learning_rate')}
Num Layers: {best_hps.get('num_layers')}
Dropout: {best_hps.get('dropout')}
""")

# Construir o modelo final com os melhores hiperparâmetros e treinar pra valer
best_model = tuner.hypermodel.build(best_hps)
history = best_model.fit(X_train_final_com_exogena, y_train_final_com_exogena,
                         epochs=100, # Aqui usamos as 100 épocas completas
                         validation_data=(X_val_final_com_exogena, y_val_final_com_exogena),
                         callbacks=[early_stopping_final])

import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

# 1. Previsão (O modelo cospe dados na escala normalizada)
predictions_scaled_com_exogena = best_model.predict(X_val_final_com_exogena)

# 2. Desfazer a escala (Voltar para Graus Celsius)
# Usamos o target_scaler que treinamos lá no início
predictions_real_com_exogena = target_scaler_com_exogena.inverse_transform(predictions_scaled_com_exogena)
y_val_real_com_exogena = target_scaler_com_exogena.inverse_transform(y_val_final_com_exogena.reshape(-1, 1))

# 3. Calcular Erro
mse_com_exogena_val = mean_squared_error(y_val_real_com_exogena, predictions_real_com_exogena)
print(f"MSE na Validação: {mse_com_exogena_val:.4f}")

# 4. Plotagem (Zoom em 200 horas para ver os detalhes)
plt.figure(figsize=(20, 6))
# Vamos plotar apenas as primeiras 200 horas para facilitar a visualização do ciclo dia/noite
limit = 10000
plt.plot(y_val_real_com_exogena[:limit], label='Temperatura Real', color='blue')
plt.plot(predictions_real_com_exogena[:limit], label='Previsão do Modelo', color='orange', linestyle='--')

plt.title('Validação: Real vs Predito (Primeiras 1000 horas)')
plt.xlabel('Horas')
plt.ylabel('Temperatura (°C)')
plt.legend()
plt.grid(True, alpha=0.5)
plt.show()